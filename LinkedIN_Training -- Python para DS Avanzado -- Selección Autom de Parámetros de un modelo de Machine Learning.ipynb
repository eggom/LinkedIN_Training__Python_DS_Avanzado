{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección Automática de Parámetros\n",
    "\n",
    "### (en un modelo de Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos Libs\n",
    "\n",
    "# (En este caso usaremos Redes Neuronales pero este programa es adaptable a multitud de modelos estimadores)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos dataset\n",
    "\n",
    "data = pd.read_csv(\"../eggomPY_Datasets/AirlineDelays/DelayedFlights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino las cols\n",
    "\n",
    "col_pred = [\"AirTime\", \"Distance\", \"TaxiIn\", \"TaxiOut\", \"DepDelay\"]\n",
    "col_target = \"ArrDelay\"\n",
    "\n",
    "# Limpiamos el dataset de NaN\n",
    "\n",
    "df = data.dropna(subset=col_pred)\n",
    "df = df.dropna(subset=[\"ArrDelay\"])\n",
    "\n",
    "# Sampleamos el dataset y lo capamos a un total de 1000 filas.\n",
    "\n",
    "df = df.sample(frac=1,replace=True, random_state=12).head(1000)\n",
    "\n",
    "# Defino un conjunto X con los datos de predicción y un conjunto con los datos objetivo\n",
    "\n",
    "X = df[col_pred]\n",
    "y = df[col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo conjuntos de train y testing\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo un transformador escalador\n",
    "\n",
    "escalador = StandardScaler()\n",
    "\n",
    "###  IMPORTANTE!!!  ##############################################################\n",
    "###                                                                             ##\n",
    "###  Fiteo el escalador con el conjunto de variables predictoras de TRAINING!!! ##\n",
    "\n",
    "escalador.fit(X_train)\n",
    "\n",
    "# Aplico el transformador escalador al conjunto de testing y training\n",
    "\n",
    "X_train = escalador.transform(X_train)\n",
    "X_test = escalador.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La función GridSearchCV\n",
    "\n",
    "Esta función ayuda para la búsqueda automática de hiperparámetros óptimos de los modelos de estimación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La importamos\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comenzamos a trabajar sobre ella.\n",
    "\n",
    "# Creamos un diccionario de parámetros que serán los parámetros los cuales queremos encontrar el óptimo.\n",
    "\n",
    "params = {\"alpha\" : [0.000001, 0.0001, 0.01, 0.1],\n",
    "          \"hidden_layer_sizes\" : [2, 5, 10, 50, 100],\n",
    "          \"solver\" : [\"lbfgs\", \"adam\"],\n",
    "          \"learning_rate\" : [\"constant\", \"adaptive\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el objeto de red neuronal\n",
    "\n",
    "nn = MLPRegressor(warm_start=True, max_iter=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(100,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=80000, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_stat...huffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=True),\n",
       "             iid='deprecated', n_jobs=-2,\n",
       "             param_grid={'alpha': [1e-06, 0.0001, 0.01, 0.1],\n",
       "                         'hidden_layer_sizes': [2, 5, 10, 50, 100],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['lbfgs', 'adam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora sí, llamo al GridSearchCV\n",
    "\n",
    "clf = GridSearchCV(nn, params, cv=5, n_jobs=-2)\n",
    "\n",
    "# Y lo fiteo (con todo el dataset)\n",
    "\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-06, 'hidden_layer_sizes': 100, 'learning_rate': 'adaptive', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "# Esta información de aquí es bastante ininteligible. Lo que nos interesa es saber cuál es el mejor modelo...\n",
    "\n",
    "# ¿Cómo podemos hacerlo?\n",
    "\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967841267627119"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Otros parámetros que ofrece:\n",
    "\n",
    "clf.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
